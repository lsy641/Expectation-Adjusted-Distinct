{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOz4aa/TX6hTLDtXGY5NNvI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsy641/Expectation-Adjusted-Distinct/blob/main/EAD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lseIhMzJrUbj"
      },
      "outputs": [],
      "source": [
        "import nltk\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A guideline of using EAD\n",
        "\n",
        "## Formula\n",
        "\n",
        "$EAD = \\frac{N}{V(1-(\\frac{V-1}{V})^{C})}$\n",
        "\n",
        "$N$ - The number of distinct tokens  \n",
        "$V$ - The vocabulary size  \n",
        "$C$ - The number of total tokens  \n",
        "\n",
        "## Steps\n",
        "1. Determine the vocabulary size  \n",
        "2. Validate EAD on the training set  \n",
        "3. Calculate EAD score on the test set  \n",
        "\n"
      ],
      "metadata": {
        "id": "1i1Q4Oz0rYF_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Determine the vocabulary size\n",
        "\n",
        "### Rules of thumb \n",
        "1. It is an empiracal and posterior approach to determining a vocabulary size. It is not a guide of vocabulary creating.\n",
        "\n",
        "2. The posterior assumption here means, supporse you have known the methods that are going to be evaluated, and these methods may adopt different vocabularies, now we have to determine a united value of vocabulary size for comparing these methods by calculating EAD scores.\n",
        "\n",
        "\n",
        "### Criterion\n",
        "\n",
        "\n",
        "|Scenarios|Desicion|\n",
        "|-|-|\n",
        "|Only one method (e.g., a benchmark work) | Directly use the size of vocabulary adopted by this method|\n",
        "|Several methods which are all not built based on large-scale pretrained models| Apply a third-party tokenizer to build the vocabulary for the dataset, and use the size of this vocabulary.|\n",
        "|Several methods which are built based on large-scale pretrained models| Directly use the largest vocabulary size among all vocabularies of the methods|\n",
        "|Some methods built on pretrained models, some are not | We never consider this situation due to the infair comparison problem |"
      ],
      "metadata": {
        "id": "chBGMyOVt7Yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Validate EAD on the training set\n",
        "\n"
      ],
      "metadata": {
        "id": "YeC_Vv23_BEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dHaCJSC-rZ3i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}